{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction au Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Le Big Data fait référence a la collectionde données caractérisées par un `volume`, une `vélocité` et une `variété` si grands que leur transformation en valeur utilisable requiert l’utilisation de technologies et de méthodes analytiques spécifiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Volume - pas d'échantillonnage, on observe et mesure tout\n",
    "* Vélocité - les données et les résultats sont souvent disponibles en temps réel\n",
    "* Variété - puise dans les données textuelles, les photos, audio / vidéo et complète généralement les pièces manquantes en fusionnant plusieurs sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![bigdata.png](images/bigdata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pourquoi le Big Data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*“There was 5 exabytes of information created between the dawn of civilization through 2003, but that much information is now created every 2 days, and the pace is increasing.”*\n",
    "\n",
    "-- Eric Schmidt, PDG Google, 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Augmentation exponentielle de la quantité de données non structurées \n",
    "    - Email, chat, blog, web, musique, photo, vidéo, etc.\n",
    "* Augmentation de la capacité de stockage et d’analyse \n",
    "    - L’utilisation de plusieurs machines en parallèle devient accessible\n",
    "* Les technologies existantes ne sont pas conçues pour ingérer ces données \n",
    "    - Base de données relationnelles, tableurs (Excel), etc.\n",
    "* De “nouvelles” technologies et techniques d’analyse sont nécessaires\n",
    "    - “Google File System” - Google 2003\n",
    "    - “MapReduce: Simplified Data Processing on Large Clusters” - Google, 2004\n",
    "    - Hadoop: circa 2006\n",
    "* D’où le “Big Data”: pas strictement plus de data... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les applications\n",
    "\n",
    "![bigdata-applications.png](images/bigdata-applications.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les techniques et les technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Systemes de fichiers distribués"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La base du “Big Data”: le stockage\n",
    "* Volume: une énorme quantité de stockage (à un coût raisonnable)\n",
    "* Vélocité: agrandir la capacité de manière progressive\n",
    "* Variété: un système de fichier “général”, qui permet de stocker n’importe quel genre de donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Systèmes traditionnels: SAN (Storage Area Network)\n",
    "* Coût initial (très) élevé\n",
    "* Peut atteindre une très grande capacité, mais éventuellement limitée\n",
    "    -Installer ou migrer un SAN est très coûteux (temps + $)\n",
    "* Généralement sur du matériel et/ou OS propriétaire qui ne permet pas de lancer ses propres tâches\n",
    "* Système “scale-up” plutôt que “scale-out”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![scale_up_vs_out.png](images/scale_up_vs_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hadoop Distributed File System (HDFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Du besoin est né “Google File System” qui a inspiré la création de Hadoop / HDFS\n",
    "* Hadoop Distributed File System est composé de 2 services:\n",
    "     - Namenode: service de méta-données\n",
    "     - Datanode: service de bloc de données\n",
    "* Un fichier inscrit dans HDFS sera divisé en blocs\n",
    "     - généralement de 64MB chacun\n",
    "* Les blocs sont répliqués (généralement 3x) et distribués sur plusieurs Datanode\n",
    "* Les clients du système de fichiers interrogent le Namenode pour:\n",
    "     - connaître la structure de l’arbre de fichiers\n",
    "     - découvrir où se trouvent les blocs d’un fichier\n",
    "* Les clients accèdent aux données directement auprès des Datanode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![hdfs_archi.png](images/hdfs_archi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Les fichiers sont divisés en blocs: la perte d’un seul de ces blocs causerait une corruption du fichier\n",
    "* Les blocs sont répliqués afin de survivre à la perte d’un ou plusieurs blocs\n",
    "* Le Namenode tente de placer les blocs afin d’éviter la perte de toutes les copies d’un même bloc d’un seul coup (défaillance d’un “rack” ou d’une “switch”)\n",
    "     - “Rack-awareness”\n",
    "* Les blocs peuvent être placés n’importe où, le client doit interroger le Namenode pour trouver un bloc\n",
    "* Un Namenode “stand-by” peut être déployé\n",
    "     - Nécessite d’autres services: Journalnode\n",
    "     - Basculement automatique: Zookeeper et “zkfc”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Avantages:\n",
    "     - En production dans des milliers de compagnies (“battle-hardened”)\n",
    "     - Documentation\n",
    "     - Compatibilité - pratiquement tout l’écosystème “Big Data” parle HDFS\n",
    "     - Disponibilité du support (les “vendeurs” Hadoop)\n",
    "* Désavantages:\n",
    "     - La configuration “HA” est complexe et fragile\n",
    "     - Ne supporte que la réplication pour éviter la perte de données\n",
    "     - Aucune capacité de fédération (grappes de HDFS)\n",
    "     - La nécessité d’interroger le Namenode pour chaque lecture\n",
    "     - Nombre de blocs limité par l’espace mémoire du Namenode (Scale-up du Namenode)\n",
    "     - Relativement lent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Il existe d'autres systemes de fichiers distribues mais leur etude sort du scope de ce cours. Parmi eux on peut citer:\n",
    "* Cloud Storage de Google\n",
    "* S3 d'Amazon\n",
    "* CEPH de RedHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmes distribués"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Historiquement dominés par des systèmes haute-performance\n",
    "    - problèmes “cpu-bound”, peu de données, calculs complexes\n",
    "    - p. ex: MPI (message passing interface), les données sont envoyées aux agents, le calcul effectué et les résultats retournés au “coordonnateur”\n",
    "* Afin de traiter de très grandes quantités de données, inverser la responsabilité: déplacer l’algorithme vers les données\n",
    "    - “data-locality”\n",
    "- Afin de maximiser le parallélisme: réduire la dépendance entre les “agents”\n",
    "- Formalisation: map / reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MapReduce (MR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Algorithme composé de 2 étapes conceptuelles\n",
    "     - map - transformation des données en paires de clé-valeur\n",
    "     - reduce - opération d'agrégation (somme, moyenne, etc.) par clé\n",
    "* L’implémentation nécessite plus de 2 étapes, mais elles sont généralement transparentes pour le programmeur\n",
    "* Sa résilience et son parallélisme sont ce qui le rendent particulièrement intéressant pour le Big-Data\n",
    "     - “Embarassingly parallel”\n",
    "     - Capacité de redémarrer n’importe quelle sous-étape (tant que les données source existent)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![map_reduce.png](images/map_reduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![map_reduce_exple.png](images/map_reduce_exple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* À moins d’avoir un problème très simple, une seule phase M/R n’est pas suffisante\n",
    "* Généralement, on doit écrire plusieurs phases et les exécuter en chaîne\n",
    "* Manuellement:\n",
    "    - laborieux\n",
    "    - sujet à l’erreur\n",
    "    - possibilités d’optimisations potentiellement perdues\n",
    "* Plusieurs abstractions ont été créées\n",
    "    - Certaines ont des optimisations intéressantes (map-side aggregation)\n",
    "    - Écrire le Map/Reduce directement n’est pas tellement conseillé aujourd’hui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Hive\n",
    "    - “compile” le SQL en chaîne de phases M/R\n",
    "    - permet la gestion de données structurées (tabulaires)\n",
    "    - s’adresse principalement aux analystes d’affaires (BI), création de rapports, etc.\n",
    "- Pig\n",
    "    - langage haut-niveau (quelques emprunts à SQL) compilé en phases M/R\n",
    "    - s’adresse principalement aux programmeurs / chercheurs\n",
    "* Cascading\n",
    "    - abstraction de “pipes-and-filters” sur Hadoop\n",
    "    - contient un optimiseur d’exécution (plan logique vs. plan physique)\n",
    "    - interface java, scala, clojure, ruby, python et SQL\n",
    "    - s’adresse aux programmeurs\n",
    "* et beaucoup d’autres..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Ré-implémentation d’une plateforme de calcul distribué\n",
    "    - contient les mêmes étapes conceptuelles que Map/Reduce\n",
    "    - n’utilise pas Map/Reduce de Hadoop\n",
    "    - plan d’exécution plus sophistiqué\n",
    "    - p. ex.: ne nécessite pas l’écriture sur disque à chaque étape\n",
    "* Unité opérationnelle est le RDD: resilient distributed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![rdd.png](images/rdd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![rdd_lineage.png](images/rdd_lineage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Spark est une plateforme: une même abstraction pour différents cas d’usage\n",
    "    - spark: tâches “batch”\n",
    "    - spark-streaming: tâches en flux continu de données\n",
    "    - spark-mllib: apprentissage machine\n",
    "    - spark-graphx: manipulation de graph\n",
    "    - spark-sql: abstraction SQL\n",
    "    - spark-R: exécution de R sur spark\n",
    "    - pyspark: exécution de python sur spark\n",
    "    - des dizaines d’extensions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Streaming vs. batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Initialement, le big-data opérait en “batch”\n",
    "    - création d’index, rapports, etc. à chaque jour (24 h)\n",
    "    - pression d’obtenir des résultats de plus en plus rapidement\n",
    "* Problème fondamental: durée d’une tâche batch doit être < interval entre les résultats\n",
    "* Nécessité de pouvoir calculer “incrémentalement” en flux continu\n",
    "    - p. ex.: opérer sur chaque “tweet”\n",
    "* Différentes plateformes sont créées:\n",
    "    - Storm (Twitter), Samza (LinkedIn), Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Spark streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![spark_streaming.png](images/spark_streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dstream transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![dstream_trans.png](images/dstream_trans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Initialement, les tâches batches sont distinctes des tâches en flux \n",
    "    - duplication de “logique d’affaire”\n",
    "* Les tâches en flux calculent incrémentalement (possiblement de manière inexacte)\n",
    "* Les tâches batches sont utilisées pour “réparer”, s’assurer de l’exactitude des données\n",
    "    - ou simplement complémenter\n",
    "* C’est le “lambda architecture”\n",
    "    - Architecture qui utilise des processus batch et en flux\n",
    "* Spark permet aujourd’hui d’unifier les 2 mondes\n",
    "    - Le mode d’opération d’une tâche est un détail de déploiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Systèmes de base de donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Technologies - systèmes de base de données\n",
    "* Les paradigmes de batch et de flux sont insuffisants\n",
    "    - Il est aussi nécessaire de lire et écrire aléatoirement (random read/write)\n",
    "* Les bases de données traditionnelles (du type scale-up) ne sont pas appropriées\n",
    "    - Volume: un seul serveur ne peut plus contenir toutes les données\n",
    "    - Vélocité: la bande passante d’un seul serveur ne peut pas soutenir le taux de requêtes\n",
    "    - Variété: les données ne sont pas toutes tabulaires (relationnelles)\n",
    "* C’est la naissance du “NoSQL”\n",
    "    - un pauvre choix de nom\n",
    "    - ne décrit pas ce que le système est, mais plutôt ce qu’il n’est pas\n",
    "    - plusieurs BD “NoSQL” ont une interface SQL (ou simili-SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### NoSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Généralement (et non strictement), une BD NoSQL:\n",
    "    - offre un paradigme d’accès ou stockage non relationnel\n",
    "    - est distribuée\n",
    "    - offre une certaine forme de capacité “scale-out”\n",
    "    - utilise un design simple (qui offre parfois peu de fonctionnalités)\n",
    "    - utilise une architecture sans point de défaillance unique\n",
    "* Étant donné le design simple, une BD NoSQL peut:\n",
    "    - soutenir un taux de requête très grand\n",
    "    - survivre à des défaillances réseau ou de noeud\n",
    "    - offrir une capacité très grande de stockage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Le NoSQL n’est pas magique: on échange les garanties des BD traditionnelles contre ces avantages:\n",
    "    - pas de transaction (begin, commit / rollback)\n",
    "    - perte des garanties de durabilité (perte d’une écriture confirmée)\n",
    "    - face aux défaillances réseau, doit choisir entre cohérence et disponibilité\n",
    "* De nombreux autres problèmes:\n",
    "    - projets immatures: nombreux bugs, perte de données en production (même sans défaillance)\n",
    "    - défaillance architecturales fondamentales: algorithmes de consensus brisé\n",
    "    - installation et/ou opérations parfois très complexe\n",
    "    - très peu, voire aucun support pour les entreprises (nécessite expertise interne)\n",
    "* Ce sont, malgré tout, des outils indispensables\n",
    "    - généralement, le choix se limite à une ou deux technologies\n",
    "    - le choix est basé sur les garanties fournies ainsi que la “famille”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Les familles (selon le paradigme d’accès): \n",
    "    - Document (p. ex. MongoDB, Elasticsearch)\n",
    "    - Clé-valeur / famille de colonnes (p.ex. HBase, Cassandra)\n",
    "    - Graphe\n",
    "    - Structuré / semi-structuré\n",
    "* Non exhaustif, c’est une catégorisation parmi d’autres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* Les 3 Vs du Big Data ont poussé les limites des systèmes traditionnels\n",
    "* Nécessaire d’opérer sur plusieurs noeuds en parallèle\n",
    "* De nouvelles techniques et technologies ont vu le jour\n",
    "    - systèmes de fichiers distribués\n",
    "    - algorithmes distribués\n",
    "    - systèmes de base de données distribués\n",
    "* Les systèmes distribués sont complexes\n",
    "    - doivent faire des compromis\n",
    "    - ces compromis dictent les caractéristiques fondamentales de ces systèmes\n",
    "    - important de bien les connaître\n",
    "* De nouvelles plateformes émergent pour simplifier la gestion de ces systèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[ETS 2017.07 - Philippe Laflamme](https://cours.etsmtl.ca/log660/public_docs/acetates/BigData_Technologies_PL.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
